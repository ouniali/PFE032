{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. sklearn PCA basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.78910648e+03,   5.19040274e+00],\n",
       "       [  3.23005437e+03,   4.41130144e+00],\n",
       "       [ -7.81999212e+02,  -3.11817922e+00],\n",
       "       [  3.41051325e+02,  -6.48352497e+00]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([[10001,2,55], [16020,4,11,], [12008,6,33], [13131,8,22]])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "pca.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better to normalize feature before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.36863319,  0.38298087],\n",
       "       [ 1.50952734,  1.23481789],\n",
       "       [-0.14360068, -0.58040917],\n",
       "       [ 1.00270653, -1.03738959]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=np.array([[10001,2,55], [16020,4,11], [12008,6,33], [13131,8,22]])\n",
    "X_scaler = StandardScaler()\n",
    "x = X_scaler.fit_transform(x)\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(x)\n",
    "pca.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PCA calculation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.2817325 , -1.34164079,  1.52127766],\n",
       "       [ 1.48440157, -0.4472136 , -1.18321596],\n",
       "       [-0.35938143,  0.4472136 ,  0.16903085],\n",
       "       [ 0.15671236,  1.34164079, -0.50709255]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x=np.array([[10001,2,55], [16020,4,11], [12008,6,33], [13131,8,22]])\n",
    "X_scaler = StandardScaler()\n",
    "x = X_scaler.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. cov matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33333333,  0.36843716, -1.28215095],\n",
       "       [ 0.36843716,  1.33333333, -0.70553368],\n",
       "       [-1.28215095, -0.70553368,  1.33333333]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1\n",
    "m = 4 # sample number\n",
    "cov_mat = np.dot(x.transpose(),x)/(m-1) # 协方差矩阵\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33333333,  0.36843716, -1.28215095],\n",
       "       [ 0.36843716,  1.33333333, -0.70553368],\n",
       "       [-1.28215095, -0.70553368,  1.33333333]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2\n",
    "cov_mat = np.cov(x, rowvar = 0)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.36863319,  0.38298087],\n",
       "       [-1.50952734,  1.23481789],\n",
       "       [ 0.14360068, -0.58040917],\n",
       "       [-1.00270653, -1.03738959]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = cov_mat\n",
    "[U,S,V] = np.linalg.svd(sigma) # 奇异值分解\n",
    "Ur = U[:,0:2]\n",
    "z = np.dot(x, Ur)\n",
    "z# 降维结果z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**这里降维的结果z（Out[118]）与用sklearn中PCA方法降维得到的结果Out[85]相同**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.28505803, -1.34271509,  1.51751098],\n",
       "       [ 1.48450422, -0.44718044, -1.18309969],\n",
       "       [-0.34955552,  0.45038782,  0.18016022],\n",
       "       [ 0.15010934,  1.3395077 , -0.51457151]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(z, Ur.transpose())# 数据复原，即x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2817325 , -1.34164079,  1.52127766],\n",
       "       [ 1.48440157, -0.4472136 , -1.18321596],\n",
       "       [-0.35938143,  0.4472136 ,  0.16903085],\n",
       "       [ 0.15671236,  1.34164079, -0.50709255]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # 复原后的数据Out[103]与压缩之前的x(Out[104])没有区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99996991682077252"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(S[0]+S[1])/(S[0]+S[1]+S[2])# 从三维降到二维，保留了99.997%的差异"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. How to choose k by sklearn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "F:\\Users\\bin_yin\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.36863319,  0.38298087],\n",
       "       [ 1.50952734,  1.23481789],\n",
       "       [-0.14360068, -0.58040917],\n",
       "       [ 1.00270653, -1.03738959]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x=np.array([[10001,2,55], [16020,4,11], [12008,6,33], [13131,8,22]])\n",
    "\n",
    "# feature normalization (feature scaling)\n",
    "X_scaler = StandardScaler()\n",
    "x = X_scaler.fit_transform(x)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.9)# 保证降维后的数据保持90%的信息\n",
    "pca.fit(x)\n",
    "pca.transform(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**从结果中，看到列数从3变为2，说明为了保证降维后的数据保持90%的信息，可以降到2维**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
